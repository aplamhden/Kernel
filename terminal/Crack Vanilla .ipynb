{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import keras\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from random import shuffle\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "import tensorflow as tf\n",
    "from ssd_functions_2 import *\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikos\\Desktop\\Dec_ 2017\\Crack vanilla\\raccoon_dataset-master\n"
     ]
    }
   ],
   "source": [
    "cd \"C:/Users/Nikos/Desktop/Dec_ 2017/Crack vanilla/raccoon_dataset-master\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?????\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "np.set_printoptions(suppress=True)\n",
    "###  constants, priors and bbox util\n",
    "NUM_CLASSES = 2\n",
    "input_shape = (300, 300, 3)\n",
    "priors = pickle.load(open('prior_boxes_ssd300.pkl', 'rb'))\n",
    "bbox_util = BBoxUtility(NUM_CLASSES, priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### csv read, dictionary generation and train-validation split\n",
    "our_data=pd.read_csv('crack2.csv')\n",
    "our_gt=dict()\n",
    "old = None\n",
    "for index,row in our_data.iterrows():\n",
    "    if old == row[0]:   \n",
    "        a=np.array([row[4]/row[1],row[5]/row[2],row[6]/row[1],row[7]/row[2],1])\n",
    "        our_gt[row[0]]=np.array([a,b])\n",
    "       \n",
    "    else:\n",
    "        our_gt[row[0]]=np.array([row[4]/row[1],row[5]/row[2],row[6]/row[1],row[7]/row[2],1]) \n",
    "        b=our_gt[row[0]]\n",
    "        our_gt[row[0]]=np.reshape(our_gt[row[0]],(-1,5))\n",
    "        \n",
    "    old = row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####create keys from dictionary\n",
    "#keys = sorted(our_gt.keys())\n",
    "#shuffle(keys)\n",
    "#with open('outfile_175', 'wb') as fp:\n",
    "   #pickle.dump(keys, fp)\n",
    "with open ('outfile_175', 'rb') as fp:\n",
    "    keys = pickle.load(fp)\n",
    "num_train = int(round(0.8 * len(keys)))\n",
    "train_keys = keys[:num_train]\n",
    "val_keys = keys[num_train:]\n",
    "num_val = len(val_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####  data augmentation class\n",
    "class Generator(object):\n",
    "    def __init__(self, gt, bbox_util,\n",
    "                 batch_size, path_prefix,\n",
    "                 train_keys, val_keys, image_size,\n",
    "                 saturation_var=0.5,\n",
    "                 brightness_var=0.5,\n",
    "                 contrast_var=0.5,\n",
    "                 lighting_std=0.5,\n",
    "                 hflip_prob=0.5,\n",
    "                 vflip_prob=0.5,\n",
    "                 do_crop=True,\n",
    "                 crop_area_range=[0.75, 1.0],\n",
    "                 aspect_ratio_range=[3./4., 4./3.]):\n",
    "        self.gt = gt\n",
    "        self.bbox_util = bbox_util\n",
    "        self.batch_size = batch_size\n",
    "        self.path_prefix = path_prefix\n",
    "        self.train_keys = train_keys\n",
    "        self.val_keys = val_keys\n",
    "        self.train_batches = len(train_keys)\n",
    "        self.val_batches = len(val_keys)\n",
    "        self.image_size = image_size\n",
    "        self.color_jitter = []\n",
    "        if saturation_var:\n",
    "            self.saturation_var = saturation_var\n",
    "            self.color_jitter.append(self.saturation)\n",
    "        if brightness_var:\n",
    "            self.brightness_var = brightness_var\n",
    "            self.color_jitter.append(self.brightness)\n",
    "        if contrast_var:\n",
    "            self.contrast_var = contrast_var\n",
    "            self.color_jitter.append(self.contrast)\n",
    "        self.lighting_std = lighting_std\n",
    "        self.hflip_prob = hflip_prob\n",
    "        self.vflip_prob = vflip_prob\n",
    "        self.do_crop = do_crop\n",
    "        self.crop_area_range = crop_area_range\n",
    "        self.aspect_ratio_range = aspect_ratio_range\n",
    "        \n",
    "    def grayscale(self, rgb):\n",
    "        return rgb.dot([0.299, 0.587, 0.114])\n",
    "\n",
    "    def saturation(self, rgb):\n",
    "        gs = self.grayscale(rgb)\n",
    "        alpha = 2 * np.random.random() * self.saturation_var \n",
    "        alpha += 1 - self.saturation_var\n",
    "        rgb = rgb * alpha + (1 - alpha) * gs[:, :, None]\n",
    "        return np.clip(rgb, 0, 255)\n",
    "\n",
    "    def brightness(self, rgb):\n",
    "        alpha = 2 * np.random.random() * self.brightness_var \n",
    "        alpha += 1 - self.saturation_var\n",
    "        rgb = rgb * alpha\n",
    "        return np.clip(rgb, 0, 255)\n",
    "\n",
    "    def contrast(self, rgb):\n",
    "        gs = self.grayscale(rgb).mean() * np.ones_like(rgb)\n",
    "        alpha = 2 * np.random.random() * self.contrast_var \n",
    "        alpha += 1 - self.contrast_var\n",
    "        rgb = rgb * alpha + (1 - alpha) * gs\n",
    "        return np.clip(rgb, 0, 255)\n",
    "\n",
    "    def lighting(self, img):\n",
    "        cov = np.cov(img.reshape(-1, 3) / 255.0, rowvar=False)\n",
    "        eigval, eigvec = np.linalg.eigh(cov)\n",
    "        noise = np.random.randn(3) * self.lighting_std\n",
    "        noise = eigvec.dot(eigval * noise) * 255\n",
    "        img += noise\n",
    "        return np.clip(img, 0, 255)\n",
    "    \n",
    "    def horizontal_flip(self, img, y):\n",
    "        if np.random.random() < self.hflip_prob:\n",
    "            img = img[:, ::-1]\n",
    "            y[:, [0, 2]] = 1 - y[:, [2, 0]]\n",
    "        return img, y\n",
    "    \n",
    "    def vertical_flip(self, img, y):\n",
    "        if np.random.random() < self.vflip_prob:\n",
    "            img = img[::-1]\n",
    "            y[:, [1, 3]] = 1 - y[:, [3, 1]]\n",
    "        return img, y\n",
    "    \n",
    "    def random_sized_crop(self, img, targets):\n",
    "        img_w = img.shape[1]\n",
    "        img_h = img.shape[0]\n",
    "        img_area = img_w * img_h\n",
    "        random_scale = np.random.random()\n",
    "        random_scale *= (self.crop_area_range[1] -\n",
    "                         self.crop_area_range[0])\n",
    "        random_scale += self.crop_area_range[0]\n",
    "        target_area = random_scale * img_area\n",
    "        random_ratio = np.random.random()\n",
    "        random_ratio *= (self.aspect_ratio_range[1] -\n",
    "                         self.aspect_ratio_range[0])\n",
    "        random_ratio += self.aspect_ratio_range[0]\n",
    "        w = np.round(np.sqrt(target_area * random_ratio))     \n",
    "        h = np.round(np.sqrt(target_area / random_ratio))\n",
    "        if np.random.random() < 0.5:\n",
    "            w, h = h, w\n",
    "        w = min(w, img_w)\n",
    "        w_rel = w / img_w\n",
    "        w = int(w)\n",
    "        h = min(h, img_h)\n",
    "        h_rel = h / img_h\n",
    "        h = int(h)\n",
    "        x = np.random.random() * (img_w - w)\n",
    "        x_rel = x / img_w\n",
    "        x = int(x)\n",
    "        y = np.random.random() * (img_h - h)\n",
    "        y_rel = y / img_h\n",
    "        y = int(y)\n",
    "        img = img[y:y+h, x:x+w]\n",
    "        new_targets = []\n",
    "        for box in targets:\n",
    "            cx = 0.5 * (box[0] + box[2])\n",
    "            cy = 0.5 * (box[1] + box[3])\n",
    "            if (x_rel < cx < x_rel + w_rel and\n",
    "                y_rel < cy < y_rel + h_rel):\n",
    "                xmin = (box[0] - x_rel) / w_rel\n",
    "                ymin = (box[1] - y_rel) / h_rel\n",
    "                xmax = (box[2] - x_rel) / w_rel\n",
    "                ymax = (box[3] - y_rel) / h_rel\n",
    "                xmin = max(0, xmin)\n",
    "                ymin = max(0, ymin)\n",
    "                xmax = min(1, xmax)\n",
    "                ymax = min(1, ymax)\n",
    "                box[:4] = [xmin, ymin, xmax, ymax]\n",
    "                new_targets.append(box)\n",
    "        new_targets = np.asarray(new_targets).reshape(-1, targets.shape[1])\n",
    "        return img, new_targets\n",
    "    \n",
    "    def generate(self, train=True):\n",
    "        while True:\n",
    "            if train:\n",
    "                shuffle(self.train_keys)\n",
    "                keys = self.train_keys\n",
    "            else:\n",
    "                shuffle(self.val_keys)\n",
    "                keys = self.val_keys\n",
    "            inputs = []\n",
    "            targets = []\n",
    "            for key in keys:            \n",
    "                img_path = self.path_prefix + key\n",
    "                img = imread(img_path).astype('float32')\n",
    "                y = self.gt[key].copy()\n",
    "                if train and self.do_crop:\n",
    "                    img, y = self.random_sized_crop(img, y)\n",
    "                img = imresize(img, self.image_size).astype('float32')\n",
    "                if train:\n",
    "                    shuffle(self.color_jitter)\n",
    "                    for jitter in self.color_jitter:\n",
    "                        img = jitter(img)\n",
    "                    if self.lighting_std:\n",
    "                        img = self.lighting(img)\n",
    "                    if self.hflip_prob > 0:\n",
    "                        img, y = self.horizontal_flip(img, y)\n",
    "                    if self.vflip_prob > 0:\n",
    "                        img, y = self.vertical_flip(img, y)\n",
    "                y = self.bbox_util.assign_boxes(y)\n",
    "                inputs.append(img)                \n",
    "                targets.append(y)\n",
    "                if len(targets) == self.batch_size:\n",
    "                    tmp_inp = np.array(inputs)\n",
    "                    tmp_targets = np.array(targets)\n",
    "                    inputs = []\n",
    "                    targets = []\n",
    "                    yield preprocess_input(tmp_inp), tmp_targets\n",
    "#####\n",
    "def jaccard_similarity(bb,gt):\n",
    "    #to result einai (class,prob,xmin,ymin,xmax,ymax)\n",
    "    #ta ground truths sto gt einai (xmin,ymin,xmax,ymax,1). eswterikh allagh gia bb kai gt sthn idia morfh. \n",
    "    bb=bb[2:6]\n",
    "    gt=gt[:4]\n",
    "    most_left=  bb.copy() if bb [0]<=gt[0] else gt.copy()\n",
    "    not_most_left=  bb.copy() if np.array_equal(gt,most_left) else gt.copy()\n",
    "    most_high= bb.copy() if bb[3]>=gt[3] else gt.copy()\n",
    "    not_most_high=bb.copy() if np.array_equal(gt,most_high) else gt\n",
    "    overlaph= False if most_left[2]<=not_most_left[0] else True\n",
    "    overlapv= False if most_high[1]>=not_most_high[3] else True\n",
    "    int_w= min(most_left[2],not_most_left[2])-not_most_left[0] if overlaph else 0\n",
    "    int_h= np.abs(max(most_high[1],not_most_high[1])-not_most_high[3]) if overlapv else 0\n",
    "    intersection=  int_w*int_h  if (overlaph and overlapv) else 0\n",
    "    area1=(bb[2]-bb[0])*(bb[3]-bb[1])\n",
    "    area2=(gt[2]-gt[0])*(gt[3]-gt[1])\n",
    "    result= intersection/(area1 + area2 -intersection)\n",
    "    return(result)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return (recall)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return (precision)\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return (2*((precision*recall)/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikos\\appdata\\local\\conda\\conda\\envs\\python35\\lib\\site-packages\\ssd_functions_2.py:542: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  mode='concat', concat_axis=1,name='mbox_loc')\n",
      "c:\\users\\nikos\\appdata\\local\\conda\\conda\\envs\\python35\\lib\\site-packages\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "c:\\users\\nikos\\appdata\\local\\conda\\conda\\envs\\python35\\lib\\site-packages\\ssd_functions_2.py:549: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  mode='concat', concat_axis=1, name='mbox_conf')\n",
      "c:\\users\\nikos\\appdata\\local\\conda\\conda\\envs\\python35\\lib\\site-packages\\ssd_functions_2.py:557: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name='mbox_priorbox')\n",
      "c:\\users\\nikos\\appdata\\local\\conda\\conda\\envs\\python35\\lib\\site-packages\\ssd_functions_2.py:573: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name='predictions')\n"
     ]
    }
   ],
   "source": [
    "####Not trainable layers,set checkpoint,data augmentation generator,load architecture and weights\n",
    "freeze = ['input_1', 'conv1_1', 'conv1_2', 'pool1',\n",
    "          'conv2_1', 'conv2_2', 'pool2',\n",
    "          'conv3_1', 'conv3_2', 'conv3_3', 'pool3']#,\n",
    "#           'conv4_1', 'conv4_2', 'conv4_3', 'pool4']    \n",
    "#checkpointing = ModelCheckpoint('checkpoints/weights.{epoch:02d}-{val_loss:.2f}{precision:.2f}{recall:.2f}.hdf5',\n",
    "                                             #verbose=1,\n",
    "                                             #save_weights_only=True)\n",
    "#callback_list=[checkpointing]\n",
    "### \n",
    "path_prefix = '/home/ec2-user/terminal/images3/'\n",
    "gen = Generator(our_gt, bbox_util, 5, '/home/ec2-user/terminal/images3/',\n",
    "                train_keys, val_keys,\n",
    "                (input_shape[0], input_shape[1]), do_crop=False)\n",
    "\n",
    "#### specify architecture and voc weights loaded\n",
    "model = SSD300(input_shape, num_classes=NUM_CLASSES)\n",
    "model.load_weights('weights_SSD300.hdf5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_lr = 3e-4\n",
    "optim = keras.optimizers.Adam(lr=base_lr)\n",
    "# optim = keras.optimizers.RMSprop(lr=base_lr)\n",
    "# optim = keras.optimizers.SGD(lr=base_lr, momentum=0.9, decay=decay, nesterov=True)\n",
    "model.compile(optimizer=optim,\n",
    "              #loss=MultiboxLoss(NUM_CLASSES, neg_pos_ratio=2.0).compute_loss,metrics=[precision, recall, f1])\n",
    "\t\t\t  loss=MultiboxLoss(NUM_CLASSES, neg_pos_ratio=2.0).compute_loss)\n",
    "for L in model.layers:\n",
    "    if L.name in freeze:\n",
    "        L.trainable = False\n",
    "###  learning rate, optimizers and compilation\n",
    "def schedule(epoch, decay=0.9):\n",
    "    return base_lr * decay**(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  epochs specification and training\n",
    "nb_epoch = 2\n",
    "detect_thr=0.5\n",
    "conf_thr=.4\n",
    "history = model.fit_generator(gen.generate(True), gen.train_batches,\n",
    "                              nb_epoch, verbose=1,\n",
    "                              validation_data=gen.generate(False),\n",
    "                              nb_val_samples=gen.val_batches,\n",
    "                              nb_worker=1)\n",
    " \n",
    "model.save('model_aws.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_prefix = 'C:/Users/Nikos/Desktop/Dec_ 2017/Crack vanilla/raccoon_dataset-master/images3/'\n",
    "#predictions on validation set\n",
    "inputs = []\n",
    "images = []\n",
    "for i in range(len(sorted(val_keys))):\n",
    "    img_path = path_prefix + sorted(val_keys)[i]\n",
    "    img = image.load_img(img_path, target_size=(300, 300))\n",
    "    img = image.img_to_array(img)\n",
    "    images.append(imread(img_path))\n",
    "    inputs.append(img.copy())\n",
    "    \n",
    "inputs = preprocess_input(np.array(inputs))\n",
    "preds = model.predict(inputs, batch_size=1, verbose=1)\n",
    "results = bbox_util.detection_out(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#red ground truth boxes,green top three(3) prediction boxes\n",
    "import heapq\n",
    "for i, img in enumerate(images):\n",
    "    k=i\n",
    "    # Parse the outputs.\n",
    "    det_label = results[i][:, 0]\n",
    "    det_conf = results[i][:, 1]\n",
    "    det_xmin = results[i][:, 2]\n",
    "    det_ymin = results[i][:, 3]\n",
    "    det_xmax = results[i][:, 4]\n",
    "    det_ymax = results[i][:, 5]\n",
    "    m = heapq.nlargest(3,det_conf)\n",
    "    # Get detections with confidence higher than 0.62\n",
    "    #top_indices = [i for i, conf in enumerate(det_conf) if conf >= 0.62]\n",
    "    # Get top three predictions\n",
    "    top_indices = [i for i, conf in enumerate(det_conf) if conf in m]\n",
    "    top_conf = det_conf[top_indices]\n",
    "    top_label_indices = det_label[top_indices].tolist()\n",
    "    top_xmin = det_xmin[top_indices]\n",
    "    top_ymin = det_ymin[top_indices]\n",
    "    top_xmax = det_xmax[top_indices]\n",
    "    top_ymax = det_ymax[top_indices]\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, 4)).tolist()\n",
    "      \n",
    "    \n",
    "    plt.imshow(img / 255.)\n",
    "    currentAxis = plt.gca()\n",
    "    for i in range(our_gt[sorted(val_keys)[k]].shape[0]):    \n",
    "        x_min_true = int(round(our_gt[sorted(val_keys)[k]][i][0]* img.shape[1]))\n",
    "        y_min_true = int(round(our_gt[sorted(val_keys)[k]][i][1]* img.shape[0]))\n",
    "        x_max_true = int(round(our_gt[sorted(val_keys)[k]][i][2]* img.shape[1]))\n",
    "        y_max_true = int(round(our_gt[sorted(val_keys)[k]][i][3]* img.shape[0]))\n",
    "        coords_true = (x_min_true, y_min_true), x_max_true-x_min_true+1, y_max_true-y_min_true+1\n",
    "        currentAxis.add_patch(plt.Rectangle(*coords_true, fill=False, edgecolor=\"red\", linewidth=2))\n",
    "    \n",
    "    for i in range(top_conf.shape[0]):\n",
    "        xmin = int(round(top_xmin[i] * img.shape[1]))\n",
    "        ymin = int(round(top_ymin[i] * img.shape[0]))\n",
    "        xmax = int(round(top_xmax[i] * img.shape[1]))\n",
    "        ymax = int(round(top_ymax[i] * img.shape[0]))\n",
    "        score = top_conf[i]\n",
    "        label = int(top_label_indices[i])\n",
    "#         label_name = voc_classes[label - 1]\n",
    "        display_txt = '{:0.2f}, {}'.format(score, label)\n",
    "        coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n",
    "        color = colors[label]\n",
    "        currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=2))\n",
    "        currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5})\n",
    "    #plt.savefig('{}.jpg'.format(k))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
